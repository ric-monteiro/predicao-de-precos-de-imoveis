# Previs√£o de Pre√ßos de Im√≥veis: Regress√£o Avan√ßada com o Dataset Ames

Este projeto foca na predi√ß√£o de pre√ßos de venda de im√≥veis utilizando o conjunto de dados Ames Housing, fornecido na competi√ß√£o "House Prices - Advanced Regression Techniques" do Kaggle. O objetivo principal √© desenvolver e avaliar modelos de regress√£o para estimar os pre√ßos com base em m√∫ltiplas caracter√≠sticas dos im√≥veis.

## ‚öôÔ∏è Etapas do Projeto

O desenvolvimento do projeto seguiu as seguintes etapas principais:

1.  **Carregamento e An√°lise Explorat√≥ria dos Dados (EDA)**:
    * Os conjuntos de dados de treino (`train.csv`) e teste (`test.csv`) foram carregados utilizando a biblioteca Pandas.
    * O arquivo `data_description.txt` foi consultado para entendimento das 79 vari√°veis explicativas que descrevem diversos aspectos das resid√™ncias.
    * Foi realizada uma an√°lise explorat√≥ria dos dados para visualizar distribui√ß√µes, identificar valores ausentes, outliers e entender as correla√ß√µes entre as vari√°veis e a vari√°vel alvo (`SalePrice`), utilizando bibliotecas como Matplotlib e Seaborn.

2.  **Pr√©-processamento e Engenharia de Features**:
    * Os valores ausentes identificados na etapa de EDA foram tratados utilizando estrat√©gias de imputa√ß√£o apropriadas para cada tipo de vari√°vel (num√©rica ou categ√≥rica).
    * As vari√°veis categ√≥ricas foram transformadas em representa√ß√µes num√©ricas (ex: *one-hot encoding*, *label encoding*) para compatibilidade com os algoritmos de machine learning.
    * Potencialmente, foram criadas novas *features* a partir das existentes para tentar capturar informa√ß√µes adicionais e melhorar o desempenho do modelo (ex: combina√ß√£o de `YearBuilt` e `YearRemodAdd` para representar a "idade efetiva" do im√≥vel).

3.  **Sele√ß√£o, Treinamento e Avalia√ß√£o de Modelos**:
    * Diferentes algoritmos de regress√£o foram considerados e treinados. O notebook `code.ipynb` indica o uso de Random Forest (`rf.predict`) e a importa√ß√£o de bibliotecas como TensorFlow e Yggdrasil Decision Forests (`ydf`), sugerindo a experimenta√ß√£o com modelos como *Gradient Boosted Trees* ou redes neurais.
    * O conjunto de treinamento (`train.csv`) foi utilizado para treinar os modelos. Estrat√©gias como valida√ß√£o cruzada podem ter sido empregadas para ajuste de hiperpar√¢metros e para uma avalia√ß√£o mais robusta da performance dos modelos.

4.  **Gera√ß√£o de Previs√µes e Submiss√£o**:
    * As mesmas etapas de pr√©-processamento aplicadas aos dados de treino foram replicadas no conjunto de teste (`test.csv`).
    * O modelo final treinado foi utilizado para gerar as previs√µes de `SalePrice` para cada im√≥vel no conjunto de teste.
    * As previs√µes foram formatadas no arquivo `submission.csv`, contendo as colunas `Id` e `SalePrice`, conforme as especifica√ß√µes da competi√ß√£o Kaggle. A m√©trica de avalia√ß√£o da competi√ß√£o √© o Erro Quadr√°tico M√©dio Logar√≠tmico Raiz (RMSLE) entre o logaritmo do valor previsto e o logaritmo do valor de venda observado.

## üìä Resultados

* O projeto resultou em um modelo preditivo capaz de estimar os pre√ßos de venda de im√≥veis com base nas caracter√≠sticas fornecidas.
* As previs√µes para o conjunto de teste est√£o consolidadas no arquivo `submission.csv`.
* O notebook `code.ipynb` cont√©m todo o fluxo de trabalho, desde a importa√ß√£o dos dados at√© a gera√ß√£o das previs√µes finais, detalhando as an√°lises e as etapas de modelagem.

## üíª Tecnologias Utilizadas

* **Python**: Linguagem de programa√ß√£o principal.
* **Pandas**: Para manipula√ß√£o e an√°lise de dados.
* **NumPy**: Para opera√ß√µes num√©ricas.
* **Scikit-learn**: Para pr√©-processamento, implementa√ß√£o de modelos (como Random Forest) e m√©tricas de avalia√ß√£o.
* **Matplotlib & Seaborn**: Para visualiza√ß√£o de dados.
* **TensorFlow & Yggdrasil Decision Forests (`ydf`)**: Bibliotecas para constru√ß√£o e treinamento de modelos avan√ßados de machine learning.
* **Jupyter Notebook**: Para desenvolvimento interativo, documenta√ß√£o e apresenta√ß√£o do c√≥digo.

## üöÄ Poss√≠veis Pr√≥ximos Passos

* Investigar t√©cnicas mais avan√ßadas de engenharia de *features*.
* Realizar uma otimiza√ß√£o de hiperpar√¢metros mais extensiva (ex: *Grid Search*, *Random Search*, Otimiza√ß√£o Bayesiana).
* Experimentar com diferentes arquiteturas de redes neurais ou modelos de *ensemble* mais complexos.
* Analisar os erros do modelo para identificar padr√µes e √°reas de melhoria.

---

## Cita√ß√µes

* **Competi√ß√£o Kaggle:**
    Anna Montoya and DataCanary. House Prices - Advanced Regression Techniques. [https://kaggle.com/competitions/house-prices-advanced-regression-techniques](https://kaggle.com/competitions/house-prices-advanced-regression-techniques), 2016. Kaggle.

* **Conjunto de Dados Ames Housing:**
    O conjunto de dados Ames Housing foi compilado por Dean De Cock para uso em educa√ß√£o em ci√™ncia de dados. √â uma alternativa moderna e expandida ao frequentemente citado conjunto de dados Boston Housing.